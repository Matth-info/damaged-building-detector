{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "# Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_path import path\n",
    "from PIL import Image\n",
    "\n",
    "# PyTorch Core and Utilities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Model Training and Evaluation\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSemanticSegmentation,\n",
    "    AutoImageProcessor,\n",
    "    SegformerImageProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import evaluate\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Image Transformations and Augmentations\n",
    "from torchvision import transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent.resolve() / \"data/cloud_drivendata/final/public\"\n",
    "TRAIN_FEATURES = DATA_DIR / \"train_features\"\n",
    "TRAIN_LABELS = DATA_DIR / \"train_labels\"\n",
    "\n",
    "assert TRAIN_FEATURES.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS = [\"B02\", \"B03\", \"B04\", \"B08\"]\n",
    "train_meta = pd.read_csv(DATA_DIR / \"train_metadata.csv\")\n",
    "\n",
    "def add_paths(df, feature_dir, label_dir=None, bands=BANDS):\n",
    "    \"\"\"\n",
    "    Given dataframe with a column for chip_id, returns a dataframe with a column\n",
    "    added indicating the path to each band's TIF image as \"{band}_path\", eg \"B02_path\".\n",
    "    A column is also added to the dataframe with paths to the label TIF, if the\n",
    "    path to the labels directory is provided.\n",
    "    \"\"\"\n",
    "    for band in bands:\n",
    "        df[f\"{band}_path\"] = feature_dir / df[\"chip_id\"] / f\"{band}.tif\"\n",
    "        #assert df[f\"{band}_path\"].path.exists().all()\n",
    "    if label_dir is not None:\n",
    "        df[\"label_path\"] = label_dir / (df[\"chip_id\"] + \".tif\")\n",
    "        #assert df[\"label_path\"].path.exists().all()\n",
    "\n",
    "    return df\n",
    "\n",
    "print(f\"Feature directory : {TRAIN_FEATURES}\")\n",
    "print(f\"Label directory : {TRAIN_LABELS}\")\n",
    "train_meta = add_paths(train_meta, TRAIN_FEATURES, TRAIN_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)  # set a seed for reproducibility\n",
    "\n",
    "# put 1/3 of chips into the validation set\n",
    "chip_ids = train_meta.chip_id.unique().tolist()\n",
    "val_chip_ids = random.sample(chip_ids, round(len(chip_ids) * 0.4))\n",
    "\n",
    "val_mask = train_meta.chip_id.isin(val_chip_ids)\n",
    "val = train_meta[val_mask].copy().reset_index(drop=True)\n",
    "train = train_meta[~val_mask].copy().reset_index(drop=True)\n",
    "\n",
    "# separate features from labels\n",
    "feature_cols = [\"chip_id\"] + [f\"{band}_path\" for band in BANDS]\n",
    "\n",
    "val_x = val[feature_cols].copy()\n",
    "val_y = val[[\"chip_id\", \"label_path\"]].copy()\n",
    "\n",
    "train_x = train[feature_cols].copy()\n",
    "train_y = train[[\"chip_id\", \"label_path\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSegmentationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_paths: pd.DataFrame,\n",
    "        bands: List[str],\n",
    "        y_paths: Optional[pd.DataFrame] = None,\n",
    "        transform = None,\n",
    "        mask_transform = None,\n",
    "        processor=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data = x_paths\n",
    "        self.label = y_paths\n",
    "        self.bands = bands\n",
    "        self.transform = transform\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def load_channel_pil(self, filepath: str):\n",
    "        return np.array(Image.open(filepath))\n",
    "\n",
    "    def open_mask(self, filepath: str):\n",
    "        mask = self.load_channel_pil(filepath) # 0-1 mask (no need to convert into a binary format)\n",
    "        return mask\n",
    "\n",
    "    def open_as_array(self, idx: int, invert=False):\n",
    "        band_arrs = [self.load_channel_pil(self.data.loc[idx][f\"{band}_path\"]) for band in self.bands]\n",
    "        x_arr = np.stack(band_arrs, axis=-1)\n",
    "        # Normalize\n",
    "        return (x_arr / np.iinfo(x_arr.dtype).max)\n",
    "    \n",
    "    def preprocess_batch(self, example_batch, transforms: A.Compose):\n",
    "        pixel_values = []\n",
    "        labels = []\n",
    "        for image, target in zip(example_batch[\"image\"], example_batch[\"label\"]):\n",
    "            transformed = transforms(image=image, mask=target)\n",
    "            pixel_values.append(transformed[\"image\"])\n",
    "            labels.append(transformed[\"mask\"])\n",
    "\n",
    "        pixel_values = torch.stack(pixel_values).to(torch.float)\n",
    "        labels = torch.stack(labels).to(torch.long)\n",
    "\n",
    "        return pixel_values, labels\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image = self.open_as_array(idx)\n",
    "        mask = None \n",
    "        \n",
    "        if self.label is not None:\n",
    "            mask = self.open_mask(self.label.iloc[idx]['label_path'])\n",
    "\n",
    "        # Apply transforms from almumentations for semantic segmentation\n",
    "        if self.transform is not None:\n",
    "            data = {'image': image, 'label': mask}\n",
    "            image, mask = self.preprocess_batch(example_batch = data, transforms=self.transform)\n",
    "\n",
    "        encoded_inputs = self.processor(images=image, segmentation_maps=mask, do_reduce_labels=False, return_tensors='pt')\n",
    "\n",
    "        for k,v in encoded_inputs.items():\n",
    "            encoded_inputs[k].squeeze_() # remove batch dimension\n",
    "        \n",
    "        return encoded_inputs\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # Return a string representation of the dataset\n",
    "        s = 'Dataset class with {} files'.format(self.__len__())\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils functions\n",
    "def load_channel_pil(filepath):\n",
    "        return np.array(Image.open(filepath))\n",
    "\n",
    "def true_color_img(chip_id, data_dir=TRAIN_FEATURES, load_channel_f=load_channel_pil):\n",
    "        # Open image files as arrays, optionally including NIR channel\n",
    "\n",
    "        chip_dir = data_dir / chip_id\n",
    "\n",
    "        raw_rgb = np.stack([load_channel_f(chip_dir / \"B04.tif\"),\n",
    "                            load_channel_f(chip_dir / \"B03.tif\"),\n",
    "                            load_channel_f(chip_dir / \"B02.tif\"),\n",
    "                           ], axis=-1)\n",
    "    \n",
    "        # Normalize pixel values 0-1 values\n",
    "        return raw_rgb / raw_rgb.max()\n",
    "\n",
    "def display_random_prediction(model, processor, metadata, chip_id = None, data_dir='TRAIN_FEATURES', alpha=0.5):\n",
    "    \"\"\"\n",
    "    Displays the ground truth and predicted segmentation masks overlaid on the original image.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The segmentation model.\n",
    "        processor (Callable): The processor to preprocess the images for the model.\n",
    "        metadata (DataFrame): Metadata containing chip IDs and label paths.\n",
    "        data_dir (str): Directory path containing image data.\n",
    "        alpha (float): Transparency level for overlaying the mask on the image.\n",
    "    \"\"\"\n",
    "    interpolate = not hasattr(object, 'interpolate') or not model.interpolate # if interpolate == True, an interpolation is required\n",
    "\n",
    "    list_images = os.listdir(path=data_dir)\n",
    "    if chip_id is None:\n",
    "        random_chip_id = np.random.choice(list_images)\n",
    "    else:\n",
    "        random_chip_id = list_images[chip_id]\n",
    "    \n",
    "    # Load image and ground truth from metadata and data directory\n",
    "    random_chip = metadata[metadata[\"chip_id\"]==random_chip_id].iloc[0]\n",
    "    image_np = true_color_img(random_chip.chip_id)  # Load the RGB image \n",
    "    gt = Image.open(random_chip.label_path)      # Load the ground truth mask\n",
    "    # Convert the NumPy image array to a PIL image\n",
    "    image = Image.fromarray(np.uint8(image_np*255)) # as image_np is 0-1 values we need to rescale to 0-255 scale then convert into np.unit8\n",
    "\n",
    "    # Preprocess image and make predictions\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs) # Cloud_Segformer outputs upsample logits => (1, nb_channel, heigth, width)\n",
    "\n",
    "    if interpolate:\n",
    "        outputs = nn.functional.interpolate(outputs.logits, image.size[-2:], mode=\"bilinear\", align_corners=True)\n",
    "    \n",
    "    # Apply argmax to get the predicted segmentation mask\n",
    "    pred_seg = outputs.argmax(dim=1)[0].cpu().numpy() # (height, width)\n",
    "    \n",
    "    # Convert ground truth and prediction to color overlays\n",
    "    gt_mask = np.array(gt)\n",
    "    pred_mask = pred_seg\n",
    "    \n",
    "\n",
    "    # Define a colormap for displaying the masks\n",
    "    colormap = plt.get_cmap(\"jet\")  # Use 'jet' colormap or choose as needed\n",
    "\n",
    "    # Generate overlays\n",
    "    gt_overlay = colormap(gt_mask / gt_mask.max())[:, :, :3] * 255  # normalize mask values for display\n",
    "    pred_overlay = colormap(pred_mask / pred_mask.max())[:, :, :3] * 255\n",
    "\n",
    "    # Convert overlays to PIL images\n",
    "    gt_overlay_img = Image.fromarray(gt_overlay.astype(np.uint8)).convert(\"RGBA\")\n",
    "    pred_overlay_img = Image.fromarray(pred_overlay.astype(np.uint8)).convert(\"RGBA\")\n",
    "\n",
    "    # Original image as RGBA for transparency blending\n",
    "    image_rgba = image.convert(\"RGBA\")\n",
    "\n",
    "    # Blend original image with ground truth and prediction overlays\n",
    "    gt_display = Image.blend(image_rgba, gt_overlay_img, alpha=alpha)\n",
    "    pred_display = Image.blend(image_rgba, pred_overlay_img, alpha=alpha)\n",
    "\n",
    "    # Display the original, ground truth, and prediction images side by side\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    axs[0].imshow(image)\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(gt_display)\n",
    "    axs[1].set_title(\"Ground Truth Overlay\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    axs[2].imshow(pred_display)\n",
    "    axs[2].set_title(\"Predicted Overlay\")\n",
    "    axs[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune Segformer on DrivenData Cloud Segmentation Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nvidia/segformer-b0-finetuned-ade-512-512\"\n",
    "label2id = {\"cloud\": 1, \"no_cloud\": 0 }\n",
    "id2label = {v: k for k,v in label2id.items()}\n",
    "num_labels = 2\n",
    "\n",
    "config = config = AutoConfig.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        num_labels=num_labels\n",
    "    )\n",
    "model = AutoModelForSemanticSegmentation.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    "    trust_remote_code=True,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "image_processor = AutoImageProcessor.from_pretrained(\n",
    "    model_name,\n",
    "    do_reduce_labels=False,\n",
    "    trust_remote_code=True,\n",
    "    do_rescale=False\n",
    ")\n",
    "\n",
    "# output : (batch_size, 150, 128, 128) where 150 : num_labels, h/4, w/4 \n",
    "# last layer (classifier): Conv2d(256, num_labels, kernel_size=(1, 1), stride=(1, 1))\n",
    "# output : SemanticSegmenteroutput : loss (if label given as model input ), logits , hidden states and attentions\n",
    "# In Transformer Segformer implementation, when the labels are provided the CrossEntropyloss (or BCE) is computed on upsampled logits (however non upsampled logits are returned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_prediction(model, image_processor, metadata=train_meta, data_dir=TRAIN_FEATURES, alpha=0.5, chip_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice calculation helper function\n",
    "def calculate_dice(pred_labels, labels, num_classes):\n",
    "    dice_scores = []\n",
    "    for i in range(num_classes):\n",
    "        pred_flat = (pred_labels == i).astype(int).flatten()\n",
    "        label_flat = (labels == i).astype(int).flatten()\n",
    "        intersection = np.sum(pred_flat * label_flat)\n",
    "        dice = (2.0 * intersection) / (np.sum(pred_flat) + np.sum(label_flat) + 1e-6)\n",
    "        dice_scores.append(dice)\n",
    "    return dice_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "import torch.nn.functional as F\n",
    "# Training function\n",
    "def train(model, dataloader, optimizer, scheduler, metric, epoch, writer, id2label, accelerator=None, device='cuda'):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_classes = len(id2label)\n",
    "\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss, logits = outputs.loss, outputs.logits\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        if accelerator is None:\n",
    "            loss.backward()\n",
    "        else:\n",
    "            accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Metric calculation for evaluation\n",
    "        with torch.no_grad():\n",
    "            upsampled_logits = F.interpolate(logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            predicted = upsampled_logits.argmax(dim=1)\n",
    "            metric.add_batch(predictions=predicted.cpu().numpy(), references=labels.cpu().numpy())\n",
    "\n",
    "        # Log loss to TensorBoard every 50 batches\n",
    "        if idx % 50 == 0:\n",
    "            writer.add_scalar(\"Training Loss\", loss.item(), epoch * len(dataloader) + idx)\n",
    "\n",
    "    # End of epoch, compute metrics including Dice score\n",
    "    metrics = metric.compute(num_labels=num_classes, reduce_labels=False)\n",
    "    mean_iou = metrics[\"mean_iou\"]\n",
    "    mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "    \n",
    "    # Calculate per-class Dice score and log it\n",
    "    dice_scores = calculate_dice(predicted.cpu().numpy(), labels.cpu().numpy(), num_classes)\n",
    "    for i, dice in enumerate(dice_scores):\n",
    "        writer.add_scalar(f\"Training Dice_{id2label[i]}\", dice, epoch)\n",
    "\n",
    "    writer.add_scalar(\"Training Mean IoU\", mean_iou, epoch)\n",
    "    writer.add_scalar(\"Training Mean Accuracy\", mean_accuracy, epoch)\n",
    "\n",
    "    print(f\"Epoch [{epoch}], Loss: {running_loss / len(dataloader):.4f}, Mean IoU: {mean_iou:.4f}, Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "    print(f\"Epoch [{epoch}] Dice scores: {[f'{id2label[i]}: {dice:.4f}' for i, dice in enumerate(dice_scores)]}\")\n",
    "\n",
    "# Validation function\n",
    "def validate(model, dataloader, metric, epoch, writer, id2label, device='cuda'):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    num_classes = len(id2label)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "            loss, logits = outputs.loss, outputs.logits\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Metric calculation for evaluation\n",
    "            upsampled_logits = F.interpolate(logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            predicted = upsampled_logits.argmax(dim=1)\n",
    "            metric.add_batch(predictions=predicted.cpu().numpy(), references=labels.cpu().numpy())\n",
    "\n",
    "    # Compute mean IoU and accuracy\n",
    "    metrics = metric.compute(num_labels=num_classes, reduce_labels=False)\n",
    "    mean_iou = metrics[\"mean_iou\"]\n",
    "    mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "\n",
    "    # Calculate Dice score and log it\n",
    "    dice_scores = calculate_dice(predicted.cpu().numpy(), labels.cpu().numpy(), num_classes)\n",
    "    for i, dice in enumerate(dice_scores):\n",
    "        writer.add_scalar(f\"Validation Dice_{id2label[i]}\", dice, epoch)\n",
    "\n",
    "    writer.add_scalar(\"Validation Loss\", running_loss / len(dataloader), epoch)\n",
    "    writer.add_scalar(\"Validation Mean IoU\", mean_iou, epoch)\n",
    "    writer.add_scalar(\"Validation Mean Accuracy\", mean_accuracy, epoch)\n",
    "\n",
    "    print(f\"Validation - Epoch [{epoch}], Loss: {running_loss / len(dataloader):.4f}, Mean IoU: {mean_iou:.4f}, Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "    print(f\"Validation - Epoch [{epoch}] Dice scores: {[f'{id2label[i]}: {dice:.4f}' for i, dice in enumerate(dice_scores)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SemanticSegmentationDataset(\n",
    "            x_paths=train_x,\n",
    "            bands=[\"B04\", \"B03\", \"B02\"],\n",
    "            y_paths=train_y,\n",
    "            processor=image_processor,\n",
    "            transform=None\n",
    "            \n",
    "        )\n",
    "valid_ds = SemanticSegmentationDataset(\n",
    "            x_paths=val_x,\n",
    "            bands=[\"B04\", \"B03\", \"B02\"],\n",
    "            y_paths=val_y,\n",
    "            processor=image_processor,\n",
    "            transform=None\n",
    "        )\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=8, pin_memory=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=64, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LambdaLR\n",
    "\n",
    "# Assuming model is already defined and loaded\n",
    "# optimizer setup\n",
    "learning_rate = 6e-5\n",
    "weight_decay = 0.01\n",
    "num_epochs = 50 \n",
    "total_steps = num_epochs * len(train_dl)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Warm-up and Cosine Annealing Scheduler\n",
    "warmup_steps = int(0.01 * total_steps)  # e.g., 1% of total steps as warm-up\n",
    "\n",
    "# Lambda function for warm-up\n",
    "def lr_lambda(current_step):\n",
    "    if current_step < warmup_steps:\n",
    "        return float(current_step) / float(max(1, warmup_steps))\n",
    "    return max(\n",
    "        0.0,\n",
    "        0.5 * (1.0 + torch.cos(torch.pi * (current_step - warmup_steps) / (total_steps - warmup_steps))),\n",
    "    )\n",
    "\n",
    "# LambdaLR with the custom lr_lambda\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "# define metrics \n",
    "metric = evaluate.load(\"mean_iou\")\n",
    "\n",
    "# move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set up TensorBoard writer\n",
    "log_dir = \"../runs\"\n",
    "model_dir=\"../models\"\n",
    "experiment_name=\"Segformer_DrivenData\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = os.path.join(log_dir, f\"{experiment_name}_{timestamp}\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "accelerator = Accelerator()\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Train and validate\n",
    "    train(model=model, \n",
    "        dataloader=train_dl,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler, \n",
    "        metric=metric,\n",
    "        epoch=epoch,\n",
    "        id2label=id2label,\n",
    "        writer=writer,\n",
    "        accelerator=accelerator,\n",
    "        device=device\n",
    "    )\n",
    "    validate(model=model,\n",
    "        dataloader=valid_dl, \n",
    "        metric=metric,\n",
    "        id2label=id2label,\n",
    "        epoch=epoch,\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_prediction(model, image_processor, metadata=train_meta, data_dir=TRAIN_FEATURES, alpha=0.5, chip_id=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use HuggingFace Trainer (pytorch compatible) (Not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
    "# predictions and label_ids field) and has to return a dictionary string to float.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Convert numpy array to PIL Image, maintaining the mode as grayscale for segmentation masks\n",
    "def convert_to_pil(image_array):\n",
    "    if image_array.ndim == 3 and image_array.shape[0] == 1:  # single-channel grayscale\n",
    "        image_array = image_array[0]  # drop the channel dimension\n",
    "    return Image.fromarray(image_array.astype(np.uint8))\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    logits_tensor = torch.from_numpy(logits)\n",
    "\n",
    "    # Scale logits to the size of the labels\n",
    "    logits_tensor = nn.functional.interpolate(\n",
    "        logits_tensor,\n",
    "        size=labels.shape[-2:],  # Match label dimensions\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    ).argmax(dim=1)\n",
    "\n",
    "    # Convert tensors to numpy arrays\n",
    "    pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "    true_labels = labels if isinstance(labels, np.ndarray) else np.array(labels)\n",
    "\n",
    "    # Convert predictions and references to the expected PIL image format\n",
    "    pil_predictions = [convert_to_pil(pred) for pred in pred_labels]\n",
    "    pil_references = [convert_to_pil(true_label) for true_label in true_labels]\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = metric.compute(\n",
    "        predictions=pil_predictions,\n",
    "        references=pil_references,\n",
    "        num_labels=len(id2label),\n",
    "        reduce_labels=image_processor.do_reduce_labels,\n",
    "    )\n",
    "\n",
    "    # Extract and add per-category metrics\n",
    "    per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
    "    per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
    "\n",
    "    metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
    "    metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SemanticSegmentationDataset(\n",
    "            x_paths=train_x,\n",
    "            bands=[\"B04\", \"B03\", \"B02\"],\n",
    "            y_paths=train_y,\n",
    "            processor=image_processor,\n",
    "            transform=None\n",
    "            \n",
    "        )\n",
    "valid_ds = SemanticSegmentationDataset(\n",
    "            x_paths=val_x,\n",
    "            bands=[\"B04\", \"B03\", \"B02\"],\n",
    "            y_paths=val_y,\n",
    "            processor=image_processor,\n",
    "            transform=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"mean_iou\")\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Define training arguments\n",
    "\n",
    "# Define optimized training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../outputs/segformer-b0-finetuned-cloud-detection\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_accumulation_steps=5,\n",
    "    learning_rate=6e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    logging_dir=f\"../runs/Segformer_DrivenData_{timestamp}\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    save_total_limit=3,\n",
    "    seed=42,\n",
    "    # torch compile \n",
    "    #torch_compile=True,\n",
    "    # Enable Mixed Precision\n",
    "    #fp16=True, \n",
    "    # Use efficient optimizer if available\n",
    "    optim=\"adamw_torch\",  # NVIDIA-optimized version for faster training\n",
    "    # Efficient Data Loading\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=8,\n",
    "    dataloader_persistent_workers=True,\n",
    "    \n",
    "    # Other Training Settings\n",
    "    load_best_model_at_end=True,\n",
    "    disable_tqdm=False,\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_prediction(model, image_processor, metadata=train_meta, data_dir=TRAIN_FEATURES, alpha=0.5, chip_id=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
