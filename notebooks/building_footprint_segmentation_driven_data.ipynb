{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Footprint Segmentation, a DrivenData Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files : 160\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "bucket_name = 'open-cities'\n",
    "prefix = f'ai-challenge'\n",
    "folder = \"/train_tier_1\"\n",
    "\n",
    "# required to add to the environment variable : AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY\n",
    "s3 = boto3.client('s3', endpoint_url='https://data.source.coop')\n",
    "\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "pages = paginator.paginate(Bucket=bucket_name, Prefix=prefix + folder)\n",
    "\n",
    "counter_files = 0\n",
    "for page in pages:\n",
    "    for obj in page['Contents']:\n",
    "        #print(obj['Key'])\n",
    "        counter_files +=1\n",
    "print(f\"number of files : {counter_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatisation from data loading to tile and mask generation in TIFF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm \n",
    "local_dir = \"../data/open-cities\"\n",
    "# Ensure the local directory exists\n",
    "os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "# required to add to the environment variable : AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY\n",
    "s3 = boto3.client('s3', endpoint_url='https://data.source.coop')\n",
    "\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "pages = paginator.paginate(Bucket=bucket_name, Prefix=prefix + folder)\n",
    "\n",
    "for page in pages:\n",
    "    for obj in tqdm(page.get('Contents', [])):\n",
    "        file_key = obj['Key']\n",
    "        local_file_path = os.path.join(local_dir, os.path.relpath(file_key, prefix))\n",
    "        \n",
    "        # Create any necessary subdirectories\n",
    "        os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "        \n",
    "        # Download file\n",
    "        s3.download_file(bucket_name, file_key, local_file_path)\n",
    "        #print(f\"Downloaded {file_key} to {local_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CURL_CA_BUNDLE\"] = \"/etc/ssl/certs/ca-certificates.crt\"\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import geopandas as gpd\n",
    "from pyproj import CRS\n",
    "\n",
    "from pystac import (Catalog, CatalogType, Item, Asset, Collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.features import rasterize\n",
    "from shapely.geometry import box\n",
    "\n",
    "import geopandas as gpd\n",
    "from pyproj import CRS\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class OpenCities:\n",
    "    def __init__(self, \n",
    "                 cols=None, \n",
    "                 win_size=1024,\n",
    "                 base_dir = \"../data/open-cities/train_tier_1\",\n",
    "                 target_dir=\"../data/open-cities/training_data\"):\n",
    "        \n",
    "        self.cols = cols  # Preset collections\n",
    "        self.base_dir = base_dir\n",
    "        self.location_to_scenes = self._location_to_scenes()\n",
    "        self.window_size = win_size\n",
    "        self.target_dir = target_dir\n",
    "        os.makedirs(self.target_dir + \"/images\", exist_ok=True)\n",
    "        os.makedirs(self.target_dir + \"/masks\", exist_ok=True)\n",
    "    \n",
    "    def _location_to_scenes(self):\n",
    "        \"\"\"Maps each location to a list of scene IDs, excluding those ending with '-labels'.\"\"\"\n",
    "        d = {}\n",
    "        for key in self.cols.keys():\n",
    "            for i in self.cols[key].get_all_items():\n",
    "                if not i.id.endswith('-labels'):  # Exclude items ending with '-labels'\n",
    "                    d.setdefault(key, []).append(i.id)\n",
    "        return d\n",
    "    \n",
    "    def _normalize_path(self, location, scene_id, file_name, type=\"image\"):\n",
    "        \n",
    "        if type=='image':\n",
    "            return os.path.join(self.base_dir, location, scene_id , file_name)\n",
    "        elif type=='label':\n",
    "            return os.path.join(self.base_dir, location, f\"{scene_id}-labels\" , file_name)\n",
    "        else:\n",
    "            return None \n",
    "    \n",
    "    def create_windows(self, src):\n",
    "        \"\"\"Creates windows to divide the image into tiles of specified size.\"\"\"\n",
    "        tile_size = self.window_size\n",
    "        n_tiles = (src.width // tile_size, src.height // tile_size)\n",
    "        windows = [\n",
    "            Window(i * tile_size, j * tile_size, tile_size, tile_size)\n",
    "            for i in range(n_tiles[0])\n",
    "            for j in range(n_tiles[1])\n",
    "        ]\n",
    "        return windows\n",
    "\n",
    "    def save_geochip(self, arr, chip_tfm, save_fn='test', crs='EPSG:4326', dtype='uint8'):\n",
    "        im = (arr).astype(dtype)\n",
    "\n",
    "        # check im shape, number of channels and expand into (H,W,C) if needed\n",
    "        if len(im.shape) == 3: \n",
    "            num_ch = im.shape[-1]\n",
    "        else: \n",
    "            num_ch = 1\n",
    "            im = np.expand_dims(im, -1)\n",
    "        \n",
    "        file_path = self.target_dir + \"/\" + f'{save_fn}.tif'\n",
    "\n",
    "        with rasterio.open(file_path, 'w', driver='GTiff', \n",
    "                                height=im.shape[0], width=im.shape[1],\n",
    "                                count=num_ch, dtype=im.dtype, crs=crs, transform=chip_tfm, compress='LZW') as dst:\n",
    "            \n",
    "            for ch in range(num_ch):\n",
    "                dst.write(im[:,:,ch], indexes=ch+1) #indexes start at 1\n",
    "\n",
    "    def display_image_mask(self, img_array, mask_array):\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2,figsize=(20,10))\n",
    "        ax1.imshow(img_array)\n",
    "        ax2.imshow(mask_array)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def pair_images_to_labels(self):\n",
    "        \"\"\"Pairs each image with its label and saves them as geochips.\"\"\"\n",
    "        for location, scenes in self.location_to_scenes.items():\n",
    "            for scene_id in scenes:\n",
    "                scene_item = self.cols[location].get_item(id=scene_id)\n",
    "\n",
    "                assert scene_item.assets['image'].href is not None \n",
    "\n",
    "                # Construct the image path, normalizing it\n",
    "                image_path = self._normalize_path(location, scene_id, f'{scene_id}.tif', type=\"image\")\n",
    "                if not os.path.exists(image_path):\n",
    "                    print(f\"Warning: Image file {image_path} not found, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Open the scene image\n",
    "                with rasterio.open(image_path) as raster_scene_image:\n",
    "                    list_windows = self.create_windows(raster_scene_image)\n",
    "                    list_win_boxes = [\n",
    "                        box(*rasterio.windows.bounds(w, raster_scene_image.meta[\"transform\"]))\n",
    "                        for w in list_windows\n",
    "                    ]\n",
    "\n",
    "                    # Normalize label path and check if it exists\n",
    "\n",
    "                    labels_path = self._normalize_path(location, f'{scene_id}' ,f'{scene_id}.geojson', type=\"label\")\n",
    "                    if not labels_path or not os.path.exists(labels_path):\n",
    "                        print(f\"Warning: Labels file {labels_path} not found, skipping.\")\n",
    "                        continue\n",
    "\n",
    "                    # Load building footprints (labels)\n",
    "                    scene_labels_gdf = gpd.read_file(labels_path)\n",
    "                    \n",
    "                    for i, win_box in enumerate(tqdm(list_win_boxes)):\n",
    "                        # Create GeoDataFrame for the current window box\n",
    "                        win_box_gdf = gpd.GeoDataFrame(geometry=[win_box], crs=raster_scene_image.meta[\"crs\"])\n",
    "                        win_box_gdf = win_box_gdf.to_crs(CRS.from_epsg(4326))\n",
    "\n",
    "                        # Spatial join between label footprints and tile boundaries\n",
    "                        gdf_chip = gpd.sjoin(scene_labels_gdf, win_box_gdf, how='inner')\n",
    "            \n",
    "                        # Define shapes for rasterizing\n",
    "                        burn_val = 255\n",
    "                        shapes = [(geom, burn_val) for geom in gdf_chip.geometry]\n",
    "\n",
    "                        if len(shapes) > 0:\n",
    "\n",
    "                            chip_tfm = rasterio.transform.from_bounds(\n",
    "                                *win_box_gdf.bounds.values[0], self.window_size, self.window_size\n",
    "                            )\n",
    "                            # Rasterize mask with the appropriate transform\n",
    "                            label_arr = rasterize(\n",
    "                                shapes, \n",
    "                                out_shape=(self.window_size, self.window_size), \n",
    "                                transform=chip_tfm, \n",
    "                                dtype='uint8'\n",
    "                            )\n",
    "\n",
    "                            # Extract image tile and save both image and mask\n",
    "                            win_arr = raster_scene_image.read(window=list_windows[i])\n",
    "                            win_arr = np.moveaxis(win_arr,0,2)\n",
    "                            image_title = f\"images/{scene_id}_tile_{i}\"\n",
    "                            mask_title = f\"masks/{scene_id}_tile_{i}_mask\"\n",
    "\n",
    "                            self.save_geochip(arr=win_arr, chip_tfm=chip_tfm, save_fn=image_title)\n",
    "                            self.save_geochip(arr=label_arr, chip_tfm=chip_tfm, save_fn=mask_title)\n",
    "\n",
    "                            if np.random.rand() < 0.05:\n",
    "                                self.display_image_mask(img_array=win_arr, mask_array=label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {cols.id:cols for cols in root_catalog.get_children()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_cities = OpenCities(\n",
    "    cols=cols,\n",
    "    base_dir = \"../data/open-cities/train_tier_1\",\n",
    "    target_dir=\"../data/open-cities/training_data\",\n",
    "    win_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_cities.pair_images_to_labels() # Need a lot of Disk space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training BuildingFootprint Segmentation Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a Jupyter notebook or IPython environment, run this in the first cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "def split_pytorch_dataset(data, train_ratio=0.8):\n",
    "    val_ratio = 1 - train_ratio\n",
    "    # Calculate the sizes for training and validation\n",
    "    train_size = int(train_ratio * len(data))\n",
    "    val_size = len(data) - train_size\n",
    "\n",
    "    train_dataset, val_dataset = random_split(data, [train_size, val_size])\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Augmentation Technique \n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(512, 512),\n",
    "        A.HorizontalFlip(p=0.5),  # Random horizontal flip with 50% probability\n",
    "        A.VerticalFlip(p=0.5),    # Random vertical flip with 50% probability\n",
    "        A.RandomRotate90(p=0.5),  # Random 90 degree rotation with 50% probability\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), \n",
    "        ToTensorV2(), \n",
    "    ], is_check_shapes=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing Invalid Samples:   3%|▎         | 136/3979 [00:10<04:58, 12.85it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10346.tif. Skipping this file.\n",
      "Removing Invalid Samples:   7%|▋         | 263/3979 [00:18<03:30, 17.64it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10364.tif. Skipping this file.\n",
      "Removing Invalid Samples:  11%|█         | 433/3979 [00:29<04:02, 14.61it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10348.tif. Skipping this file.\n",
      "Removing Invalid Samples:  12%|█▏        | 494/3979 [00:34<04:07, 14.06it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10359.tif. Skipping this file.\n",
      "Removing Invalid Samples:  13%|█▎        | 517/3979 [00:35<04:05, 14.09it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10444.tif. Skipping this file.\n",
      "Removing Invalid Samples:  16%|█▋        | 654/3979 [00:45<04:05, 13.56it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10454.tif. Skipping this file.\n",
      "Removing Invalid Samples:  24%|██▍       | 965/3979 [01:08<03:38, 13.77it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10443.tif. Skipping this file.\n",
      "Removing Invalid Samples:  26%|██▌       | 1020/3979 [01:12<03:42, 13.28it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10435.tif. Skipping this file.\n",
      "Removing Invalid Samples:  28%|██▊       | 1097/3979 [01:18<03:36, 13.31it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10356.tif. Skipping this file.\n",
      "Removing Invalid Samples:  30%|██▉       | 1186/3979 [01:24<03:23, 13.75it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10349.tif. Skipping this file.\n",
      "Removing Invalid Samples:  38%|███▊      | 1509/3979 [01:48<02:59, 13.79it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10438.tif. Skipping this file.\n",
      "Removing Invalid Samples:  46%|████▌     | 1838/3979 [02:12<02:35, 13.77it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10350.tif. Skipping this file.\n",
      "Removing Invalid Samples:  47%|████▋     | 1853/3979 [02:13<02:34, 13.79it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10446.tif. Skipping this file.\n",
      "Removing Invalid Samples:  47%|████▋     | 1880/3979 [02:15<02:33, 13.64it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10361.tif. Skipping this file.\n",
      "Removing Invalid Samples:  49%|████▉     | 1955/3979 [02:20<02:38, 12.75it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10436.tif. Skipping this file.\n",
      "Removing Invalid Samples:  59%|█████▉    | 2352/3979 [02:50<02:03, 13.16it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10447.tif. Skipping this file.\n",
      "Removing Invalid Samples:  60%|█████▉    | 2381/3979 [02:52<02:03, 12.95it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10354.tif. Skipping this file.\n",
      "Removing Invalid Samples:  63%|██████▎   | 2491/3979 [03:00<01:55, 12.92it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10351.tif. Skipping this file.\n",
      "Removing Invalid Samples:  67%|██████▋   | 2650/3979 [03:13<01:41, 13.06it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10449.tif. Skipping this file.\n",
      "Removing Invalid Samples:  67%|██████▋   | 2684/3979 [03:16<01:31, 14.17it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10452.tif. Skipping this file.\n",
      "Removing Invalid Samples:  77%|███████▋  | 3046/3979 [03:42<01:07, 13.75it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10363.tif. Skipping this file.\n",
      "Removing Invalid Samples:  84%|████████▍ | 3341/3979 [04:04<00:44, 14.48it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10437.tif. Skipping this file.\n",
      "Removing Invalid Samples:  84%|████████▍ | 3344/3979 [04:04<00:44, 14.41it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10453.tif. Skipping this file.\n",
      "Removing Invalid Samples:  85%|████████▌ | 3386/3979 [04:07<00:42, 13.94it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10355.tif. Skipping this file.\n",
      "Removing Invalid Samples:  87%|████████▋ | 3451/3979 [04:12<00:37, 13.94it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10362.tif. Skipping this file.\n",
      "Removing Invalid Samples:  91%|█████████ | 3619/3979 [04:24<00:27, 13.33it/s]WARNING:root:Error opening image or mask for ../data/Open-cities/images/665946_tile_10451.tif. Skipping this file.\n",
      "Removing Invalid Samples: 100%|██████████| 3979/3979 [04:50<00:00, 13.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import  OpenCities_Building_Dataset\n",
    "\n",
    "base_dir = \"../data/Open-cities\"\n",
    "image_dir = f'{base_dir}/images'\n",
    "mask_dir = f'{base_dir}/masks'\n",
    "\n",
    "data = OpenCities_Building_Dataset(\n",
    "    images_dir=image_dir,\n",
    "    masks_dir=mask_dir,\n",
    "    transform=transform,\n",
    "    filter_invalid_image=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data , valid_data = split_pytorch_dataset(data, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3162"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ResNet_UNET\n",
    "model = ResNet_UNET(in_channels=3,out_channels=2, freeze_backbone=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# Define the optimizer with parameter groups\n",
    "def get_optimizer(model, lr_backbone=1e-4, lr_upconv=1e-3, weight_decay=1e-5):\n",
    "    # Collect parameters for the backbone and the upconvs\n",
    "    backbone_params = []\n",
    "    upconv_params = []\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:  # Only include trainable parameters\n",
    "            if \"upconv\" in name:\n",
    "                upconv_params.append(param)\n",
    "            else:\n",
    "                backbone_params.append(param)\n",
    "\n",
    "    # Define the optimizer with parameter groups\n",
    "    optimizer = optim.AdamW(\n",
    "        [\n",
    "            {\"params\": backbone_params, \"lr\": lr_backbone},\n",
    "            {\"params\": upconv_params, \"lr\": lr_upconv},\n",
    "        ],\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "# Lambda function for warm-up\n",
    "def lr_lambda(current_step):\n",
    "    if current_step < warmup_steps:\n",
    "        return float(current_step) / float(max(1, warmup_steps))\n",
    "    return max(\n",
    "        0.0,\n",
    "        0.5 * (1.0 + torch.cos(torch.pi * (current_step - warmup_steps) / (total_steps - warmup_steps))),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, pin_memory=True, shuffle=True)\n",
    "val_dl = DataLoader(valid_data, batch_size=32, pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import DiceLoss, FocalLoss\n",
    "from metrics import accuracy, f1_score, iou_score, recall, precision\n",
    "optimizer = get_optimizer(model, lr_backbone=1e-4, lr_upconv=1e-3)\n",
    "params_opt = {}\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, last_epoch=-1)\n",
    "params_sc = {}\n",
    "\n",
    "criterion = FocalLoss(mode=\"multiclass\")\n",
    "# Define Metrics \n",
    "metrics = [accuracy, f1_score, iou_score, recall, precision]\n",
    "\n",
    "# Early Stopping \n",
    "early_stopping_params = {\"patience\":5, \"trigger_times\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment logs are recoded at ../runs/ResNet_Unet_OpenCities_20241119-212643\n",
      "Epoch 1\n",
      "----------\n",
      "Epoch 1 Training completed. Loss: 0.2925\n",
      "\n",
      "Metrics (Training Phase):\n",
      "\n",
      "+---------------------------+--------+\n",
      "|           Metric          | Value  |\n",
      "+---------------------------+--------+\n",
      "|          accuracy         | 0.7322 |\n",
      "|          f1_score         | 0.7322 |\n",
      "|         iou_score         | 0.6072 |\n",
      "|        sensitivity        | 0.7322 |\n",
      "| positive_predictive_value | 0.7322 |\n",
      "+---------------------------+--------+\n",
      "Epoch 1 Validation completed. Loss: 0.2609\n",
      "\n",
      "Metrics (Validation Phase):\n",
      "\n",
      "+---------------------------+--------+\n",
      "|           Metric          | Value  |\n",
      "+---------------------------+--------+\n",
      "|          accuracy         | 0.7568 |\n",
      "|          f1_score         | 0.7568 |\n",
      "|         iou_score         | 0.6388 |\n",
      "|        sensitivity        | 0.7568 |\n",
      "| positive_predictive_value | 0.7568 |\n",
      "+---------------------------+--------+\n",
      "LOSS train 0.29249433352176635 valid 0.2609354219530084\n",
      "Saving best model\n",
      "Epoch 2\n",
      "----------\n",
      "Epoch 2 Training completed. Loss: 0.2602\n",
      "\n",
      "Metrics (Training Phase):\n",
      "\n",
      "+---------------------------+--------+\n",
      "|           Metric          | Value  |\n",
      "+---------------------------+--------+\n",
      "|          accuracy         | 0.7443 |\n",
      "|          f1_score         | 0.7443 |\n",
      "|         iou_score         | 0.6234 |\n",
      "|        sensitivity        | 0.7443 |\n",
      "| positive_predictive_value | 0.7443 |\n",
      "+---------------------------+--------+\n",
      "Epoch 2 Validation completed. Loss: 0.2555\n",
      "\n",
      "Metrics (Validation Phase):\n",
      "\n",
      "+---------------------------+--------+\n",
      "|           Metric          | Value  |\n",
      "+---------------------------+--------+\n",
      "|          accuracy         | 0.7626 |\n",
      "|          f1_score         | 0.7626 |\n",
      "|         iou_score         | 0.6456 |\n",
      "|        sensitivity        | 0.7626 |\n",
      "| positive_predictive_value | 0.7626 |\n",
      "+---------------------------+--------+\n",
      "LOSS train 0.26024495576997864 valid 0.25550506344034457\n",
      "Saving best model\n",
      "Epoch 3\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from training import train \n",
    "train(\n",
    "    model=model,\n",
    "    train_dl=train_dl,\n",
    "    valid_dl=val_dl,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    params_opt=params_opt,\n",
    "    params_sc=params_sc,\n",
    "    loss_fn=criterion,\n",
    "    metrics=metrics,\n",
    "    nb_epochs=50,\n",
    "    experiment_name=\"ResNet_Unet_OpenCities\",\n",
    "    log_dir=\"../runs\",\n",
    "    model_dir=\"../models\",\n",
    "    early_stopping_params=early_stopping_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
