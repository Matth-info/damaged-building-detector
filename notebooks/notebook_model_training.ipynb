{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# In a Jupyter notebook or IPython environment, run this in the first cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Detection on LEVIR-CD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseResNetUNet(\n",
       "  (firstconv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (firstbn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (firstrelu): ReLU(inplace=True)\n",
       "  (firstmaxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (encoder1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (center): DecoderBlock(\n",
       "    (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (upsample): ConvTranspose2d(1024, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "    (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder1): DecoderBlock(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (upsample): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder2): DecoderBlock(\n",
       "    (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (upsample): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "    (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder3): DecoderBlock(\n",
       "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (upsample): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "    (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "  )\n",
       "  (final): Sequential(\n",
       "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import TinyCD, SiameseResNetUNet\n",
    "\n",
    "\"\"\"model = TinyCD(\n",
    "    bkbn_name=\"efficientnet_b4\",\n",
    "    pretrained=True,\n",
    "    output_layer_bkbn=\"3\",\n",
    "    out_channels=2,\n",
    "    freeze_backbone=False\n",
    ")\n",
    "model.to(\"cuda\")\"\"\"\n",
    "\n",
    "model = SiameseResNetUNet(\n",
    "            in_channels=3,\n",
    "            out_channels=2,\n",
    "            backbone_name=\"resnet18\",\n",
    "            pretrained=True,\n",
    "            freeze_backbone=False,\n",
    "            mode=\"conc\"\n",
    "        )\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/albumentations/core/validation.py:45: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/opt/conda/lib/python3.12/site-packages/pydantic/main.py:426: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `dict[str, any]` but got `UniformParams` with value `UniformParams(noise_type=...6, 0.0784313725490196)])` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7120 train samples.\n",
      "Loaded 1024 val samples.\n",
      "Loaded 2048 test samples.\n"
     ]
    }
   ],
   "source": [
    "from datasets import Levir_cd_dataset\n",
    "\n",
    "from training.augmentations import (\n",
    "    get_val_augmentation_pipeline,\n",
    "    get_train_augmentation_pipeline\n",
    "    )\n",
    "\n",
    "origin_dir = \"../data/Levir-cd-256\"\n",
    "train_transform = get_train_augmentation_pipeline(image_size=None, \n",
    "                                          mean = None,\n",
    "                                          std = None\n",
    "                                          )\n",
    "\n",
    "val_transform = get_val_augmentation_pipeline(image_size=None, \n",
    "                                          mean = None,\n",
    "                                          std = None\n",
    "                                          )\n",
    "train_data = Levir_cd_dataset(origin_dir=origin_dir, \n",
    "                              transform=train_transform,\n",
    "                              type = \"train\"\n",
    "                              )\n",
    "val_data = Levir_cd_dataset(origin_dir=origin_dir, \n",
    "                              transform=val_transform,\n",
    "                              type = \"val\"\n",
    "                              )\n",
    "test_data = Levir_cd_dataset(origin_dir=origin_dir, \n",
    "                              transform=val_transform,\n",
    "                              type = \"test\"\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting class frequencies: 100%|██████████| 200/200 [00:04<00:00, 41.19it/s]\n",
      "Assigning sample weights: 7120it [01:35, 74.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights :  {np.int32(0): 1.0582325839752058, np.int32(1): 18.172516342789166}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Define a Weighted Random Sampler \n",
    "from training.utils import define_weighted_random_sampler \n",
    "\n",
    "weighted_sampler, class_weights_dict = define_weighted_random_sampler(\n",
    "        dataset=train_data, \n",
    "        mask_key=\"mask\", \n",
    "        subset_size=200,\n",
    "        seed=42\n",
    "    )\n",
    "print(\"Class Weights : \", class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weights = [class_weights_dict[i] for i in range(len(class_weights_dict))]\n",
    "class_weights = [1.0, 20.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dl = DataLoader(dataset=train_data, batch_size=32, pin_memory=True, num_workers=8) #sampler=weighted_sampler)\n",
    "val_dl = DataLoader(dataset=val_data, shuffle=True, batch_size=32, pin_memory=True, num_workers=8)\n",
    "test_dl = DataLoader(dataset=test_data, shuffle=False, batch_size=32, pin_memory=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Experiment logs are recorded at ../runs/Levir_CD_Siamese_ResNet18_Unet\n",
      "INFO:root:Model Signature has been defined\n",
      "2025/01/12 18:32:55 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "INFO:root:Hyperparameters have been logged\n",
      "Testing: 100%|██████████| 64/64 [00:23<00:00,  2.75batch/s]\n",
      "INFO:root:Per-Class Performance and Overall Performance file logged as artifact\n",
      "2025/01/12 18:33:53 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/01/12 18:33:53 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Levir_CD_Siamese_ResNet18_Unet_20250112-183253 at: http://localhost:5000/#/experiments/205686240822932636/runs/f154aa45f491457080d09865b8ddfe31\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/205686240822932636\n"
     ]
    }
   ],
   "source": [
    "from training import train, testing\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch \n",
    "from metrics import iou_score, f1_score, precision, recall\n",
    "import torch.optim as optim\n",
    "from losses import Ensemble, DiceLoss\n",
    "\n",
    "mode = \"multiclass\"\n",
    "nb_epochs = 3\n",
    "\n",
    "criterion = Ensemble(\n",
    "    list_losses=[\n",
    "        torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights), reduction='mean').to(\"cuda\"), \n",
    "        DiceLoss(mode=mode)\n",
    "    ],\n",
    "    weights=[0.7,0.3]\n",
    ")\n",
    "metrics = [f1_score, iou_score]\n",
    "\n",
    "optimizer = optim.AdamW\n",
    "params_opt = {\"lr\":1e-3, \"weight_decay\":1e-2, \"amsgrad\": False}\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR\n",
    "params_sc = {\"T_max\" : 100}\n",
    "early_stopping_params = {\"patience\": 5, \"trigger_times\": 0}\n",
    "\n",
    "train(\n",
    "    model = model,\n",
    "    train_dl = train_dl,\n",
    "    valid_dl = val_dl,\n",
    "    test_dl = test_dl, \n",
    "    loss_fn = criterion,\n",
    "    optimizer = optimizer, \n",
    "    scheduler = scheduler, \n",
    "    params_opt=params_opt,\n",
    "    params_sc=params_sc,\n",
    "    metrics = metrics,\n",
    "    nb_epochs = nb_epochs,\n",
    "    experiment_name = \"Levir_CD_Siamese_ResNet18_Unet\",\n",
    "    log_dir=\"../runs\",\n",
    "    model_dir=\"../models\",\n",
    "    resume_path=None,\n",
    "    early_stopping_params = early_stopping_params,\n",
    "    image_key = \"post_image\",\n",
    "    mask_key = \"mask\",\n",
    "    num_classes = len(class_weights), \n",
    "    verbose = False,  # Adding verbose flag\n",
    "    checkpoint_interval = 10,  # Add checkpoint interval parameter\n",
    "    debug = False,  # Add debug flag for memory logging, \n",
    "    training_log_interval = 5, \n",
    "    is_mixed_precision=True,\n",
    "    reduction= \"weighted\",\n",
    "    class_weights = class_weights,\n",
    "    class_names=[\"No Change\", \"Change\"], \n",
    "    siamese=True,\n",
    "    tta=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   6%|▋         | 4/64 [00:07<01:41,  1.69s/batch]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 64/64 [01:40<00:00,  1.57s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Class Performance Metrics (TTA):\n",
      "+-----------+-----------+--------+----------+--------+--------+\n",
      "|   Class   | Precision | Recall | F1 Score |  IoU   |  Dice  |\n",
      "+-----------+-----------+--------+----------+--------+--------+\n",
      "| No Change |   0.9985  | 0.9796 |  0.9889  | 0.9781 | 0.9889 |\n",
      "|   Change  |   0.7187  | 0.9720 |  0.8263  | 0.7041 | 0.8263 |\n",
      "+-----------+-----------+--------+----------+--------+--------+\n",
      "----------------------------------------\n",
      "Overall Performance Metrics:\n",
      "  Precision (macro): 0.8586\n",
      "  Recall (macro):    0.9758\n",
      "  F1 Score (macro):  0.9076\n",
      "Metrics have been saved to ../outputs/Levir_CD_Siamese_ResNet34_Unet_with_TTA.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 64/64 [00:29<00:00,  2.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Class Performance Metrics ():\n",
      "+-----------+-----------+--------+----------+--------+--------+\n",
      "|   Class   | Precision | Recall | F1 Score |  IoU   |  Dice  |\n",
      "+-----------+-----------+--------+----------+--------+--------+\n",
      "| No Change |   0.9984  | 0.9773 |  0.9877  | 0.9758 | 0.9877 |\n",
      "|   Change  |   0.6966  | 0.9710 |  0.8113  | 0.6824 | 0.8113 |\n",
      "+-----------+-----------+--------+----------+--------+--------+\n",
      "----------------------------------------\n",
      "Overall Performance Metrics:\n",
      "  Precision (macro): 0.8475\n",
      "  Recall (macro):    0.9742\n",
      "  F1 Score (macro):  0.8995\n",
      "Metrics have been saved to ../outputs/Levir_CD_Siamese_ResNet34_Unet_without_TTA.txt\n"
     ]
    }
   ],
   "source": [
    "from metrics import compute_model_class_performance\n",
    "\n",
    "compute_model_class_performance(\n",
    "    model=model,\n",
    "    dataloader=test_dl,\n",
    "    num_classes=2,\n",
    "    device='cuda',\n",
    "    class_names=[\"No Change\", \"Change\"], \n",
    "    siamese=True,\n",
    "    image_key=\"image\",\n",
    "    mask_key=\"mask\",\n",
    "    average_mode=\"macro\",\n",
    "    output_file=\"../outputs/Levir_CD_Siamese_ResNet34_Unet_with_TTA.txt\",\n",
    "    tta=True\n",
    ")\n",
    "compute_model_class_performance(\n",
    "    model=model,\n",
    "    dataloader=test_dl,\n",
    "    num_classes=2,\n",
    "    device='cuda',\n",
    "    class_names=[\"No Change\", \"Change\"], \n",
    "    siamese=True,\n",
    "    image_key=\"image\",\n",
    "    mask_key=\"mask\",\n",
    "    average_mode=\"macro\",\n",
    "    output_file=\"../outputs/Levir_CD_Siamese_ResNet34_Unet_without_TTA.txt\",\n",
    "    tta=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
