{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a Jupyter notebook or IPython environment, run this in the first cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Detection on LEVIR-CD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /home/onyxia/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "100%|██████████| 83.3M/83.3M [00:00<00:00, 96.7MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SiameseResNetUNet(\n",
       "  (firstconv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (firstbn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (firstrelu): ReLU(inplace=True)\n",
       "  (firstmaxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (encoder1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (center): DecoderBlock(\n",
       "    (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (upsample): ConvTranspose2d(1024, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "    (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder1): DecoderBlock(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (upsample): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder2): DecoderBlock(\n",
       "    (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (upsample): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "    (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder3): DecoderBlock(\n",
       "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (upsample): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "    (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "  )\n",
       "  (final): Sequential(\n",
       "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import TinyCD, SiameseResNetUNet\n",
    "\n",
    "\"\"\"model = TinyCD(\n",
    "    bkbn_name=\"efficientnet_b4\",\n",
    "    pretrained=True,\n",
    "    output_layer_bkbn=\"3\",\n",
    "    out_channels=2,\n",
    "    freeze_backbone=False\n",
    ")\n",
    "model.to(\"cuda\")\"\"\"\n",
    "\n",
    "model = SiameseResNetUNet(\n",
    "            in_channels=3,\n",
    "            out_channels=2,\n",
    "            backbone_name=\"resnet34\",\n",
    "            pretrained=True,\n",
    "            freeze_backbone=False,\n",
    "            mode=\"conc\"\n",
    "        )\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pydantic/main.py:426: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `dict[str, any]` but got `UniformParams` with value `UniformParams(noise_type=...6, 0.0784313725490196)])` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7120 train samples.\n",
      "Loaded 1024 val samples.\n",
      "Loaded 2048 test samples.\n"
     ]
    }
   ],
   "source": [
    "from datasets import Levir_cd_dataset\n",
    "\n",
    "from training.augmentations import (\n",
    "    get_val_augmentation_pipeline,\n",
    "    get_train_augmentation_pipeline\n",
    "    )\n",
    "\n",
    "origin_dir = \"../data/Levir-cd-256\"\n",
    "train_transform = get_train_augmentation_pipeline(image_size=(256, 256), \n",
    "                                          mean = None,\n",
    "                                          std = None\n",
    "                                          )\n",
    "\n",
    "val_transform = get_val_augmentation_pipeline(image_size=(256, 256), \n",
    "                                          mean = None,\n",
    "                                          std = None\n",
    "                                          )\n",
    "train_data = Levir_cd_dataset(origin_dir=origin_dir, \n",
    "                              transform=train_transform,\n",
    "                              type = \"train\"\n",
    "                              )\n",
    "val_data = Levir_cd_dataset(origin_dir=origin_dir, \n",
    "                              transform=val_transform,\n",
    "                              type = \"val\"\n",
    "                              )\n",
    "test_data = Levir_cd_dataset(origin_dir=origin_dir, \n",
    "                              transform=val_transform,\n",
    "                              type = \"test\"\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting class frequencies: 100%|██████████| 200/200 [00:05<00:00, 33.96it/s]\n",
      "Assigning sample weights: 7120it [02:04, 57.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights :  {np.int32(1): 17.380557728750507, np.int32(0): 1.061047982404288}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Define a Weighted Random Sampler \n",
    "from training.utils import define_weighted_random_sampler \n",
    "\n",
    "weighted_sampler, class_weights_dict = define_weighted_random_sampler(\n",
    "        dataset=train_data, \n",
    "        mask_key=\"mask\", \n",
    "        subset_size=200,\n",
    "        seed=42\n",
    "    )\n",
    "print(\"Class Weights : \", class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [class_weights_dict[i] for i in range(len(class_weights_dict))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dl = DataLoader(dataset=train_data, batch_size=32, pin_memory=True, num_workers=8, sampler=weighted_sampler)\n",
    "val_dl = DataLoader(dataset=val_data, shuffle=True, batch_size=32, pin_memory=True, num_workers=8)\n",
    "test_dl = DataLoader(dataset=test_data, shuffle=False, batch_size=32, pin_memory=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Experiment logs are recorded at ../runs/Levir_CD_Siamese_ResNet18_Unet_20250106-215644\n",
      "INFO:root:Model graph has been logged\n",
      "INFO:root:Hyperparameters have been logged\n",
      "INFO:root:Epoch 1\n",
      "INFO:root:--------------------\n",
      "Epoch 1:   0%|          | 0/223 [00:00<?, ?batch/s]"
     ]
    }
   ],
   "source": [
    "from training import train, testing\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch \n",
    "from metrics import iou_score, f1_score, precision, recall\n",
    "from losses import DiceLoss, Ensemble, FocalLoss\n",
    "import torch.optim as optim\n",
    "from training.utils import define_weighted_random_sampler\n",
    "\n",
    "mode = \"multiclass\"\n",
    "nb_epochs = 60\n",
    "criterion =  torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights), reduction='mean').to(\"cuda\")\n",
    "metrics = [f1_score, iou_score]\n",
    "\n",
    "optimizer = optim.AdamW(params=filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3, weight_decay=1e-2, amsgrad=False)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "early_stopping_params = {\"patience\": 10, \"trigger_times\": 0}\n",
    "\n",
    "train(\n",
    "    model = model,\n",
    "    train_dl = train_dl,\n",
    "    valid_dl = val_dl,\n",
    "    loss_fn = criterion,\n",
    "    optimizer = optimizer, \n",
    "    scheduler = scheduler, \n",
    "    metrics = metrics,\n",
    "    nb_epochs = nb_epochs,\n",
    "    experiment_name = \"Levir_CD_Siamese_ResNet18_Unet\",\n",
    "    log_dir=\"../runs\",\n",
    "    model_dir=\"../models\",\n",
    "    resume_path=None,\n",
    "    early_stopping_params = early_stopping_params,\n",
    "    image_key = \"post_image\",\n",
    "    mask_key = \"mask\",\n",
    "    num_classes = len(class_weights), \n",
    "    verbose = False,  # Adding verbose flag\n",
    "    checkpoint_interval = 10,  # Add checkpoint interval parameter\n",
    "    debug = False,  # Add debug flag for memory logging, \n",
    "    training_log_interval = 5, \n",
    "    is_mixed_precision=True,\n",
    "    reduction= \"weighted\",\n",
    "    class_weights = class_weights,\n",
    "    siamese=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 64/64 [01:48<00:00,  1.69s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Class Performance Metrics (TTA):\n",
      "+-----------+-----------+--------+----------+--------+--------+\n",
      "|   Class   | Precision | Recall | F1 Score |  IoU   |  Dice  |\n",
      "+-----------+-----------+--------+----------+--------+--------+\n",
      "| No Change |   0.9983  | 0.9823 |  0.9902  | 0.9807 | 0.9902 |\n",
      "|   Change  |   0.7463  | 0.9687 |  0.8431  | 0.7287 | 0.8431 |\n",
      "+-----------+-----------+--------+----------+--------+--------+\n",
      "----------------------------------------\n",
      "Overall Performance Metrics:\n",
      "  Precision (macro): 0.8723\n",
      "  Recall (macro):    0.9755\n",
      "  F1 Score (macro):  0.9167\n",
      "Metrics have been saved to ../outputs/Levir_CD_Siamese_ResNet18_Unet_with_TTA.txt\n"
     ]
    }
   ],
   "source": [
    "from metrics import compute_model_class_performance\n",
    "\n",
    "compute_model_class_performance(\n",
    "    model=model,\n",
    "    dataloader=test_dl,\n",
    "    num_classes=2,\n",
    "    device='cuda',\n",
    "    class_names=[\"No Change\", \"Change\"], \n",
    "    siamese=True,\n",
    "    image_key=\"image\",\n",
    "    mask_key=\"mask\",\n",
    "    average_mode=\"macro\",\n",
    "    output_file=\"../outputs/Levir_CD_Siamese_ResNet18_Unet_with_TTA.txt\",\n",
    "    tta=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
