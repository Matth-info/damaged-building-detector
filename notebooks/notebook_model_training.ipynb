{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a Jupyter notebook or IPython environment, run this in the first cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Detection on LEVIR-CD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import TinyCD, SiameseResNetUNet\n",
    "\n",
    "\"\"\"model = TinyCD(\n",
    "    bkbn_name=\"efficientnet_b4\",\n",
    "    pretrained=True,\n",
    "    output_layer_bkbn=\"3\",\n",
    "    out_channels=2,\n",
    "    freeze_backbone=False\n",
    ")\n",
    "model.to(\"cuda\")\"\"\"\n",
    "\n",
    "model = SiameseResNetUNet(\n",
    "            in_channels=3,\n",
    "            out_channels=2,\n",
    "            backbone_name=\"resnet18\",\n",
    "            pretrained=True,\n",
    "            freeze_backbone=False,\n",
    "            mode=\"conc\"\n",
    "        )\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Levir_cd_dataset\n",
    "\n",
    "from training.augmentations import (\n",
    "    get_val_augmentation_pipeline,\n",
    "    get_train_augmentation_pipeline\n",
    "    )\n",
    "\n",
    "origin_dir = \"../data/Levir-cd-256\"\n",
    "train_transform = get_train_augmentation_pipeline(image_size=None, \n",
    "                                          mean = None,\n",
    "                                          std = None\n",
    "                                          )\n",
    "\n",
    "val_transform = get_val_augmentation_pipeline(image_size=None, \n",
    "                                          mean = None,\n",
    "                                          std = None\n",
    "                                          )\n",
    "train_data = Levir_cd_dataset(origin_dir=origin_dir, \n",
    "                              transform=train_transform,\n",
    "                              type = \"train\"\n",
    "                              )\n",
    "val_data = Levir_cd_dataset(origin_dir=origin_dir, \n",
    "                              transform=val_transform,\n",
    "                              type = \"val\"\n",
    "                              )\n",
    "test_data = Levir_cd_dataset(origin_dir=origin_dir, \n",
    "                              transform=val_transform,\n",
    "                              type = \"test\"\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Weighted Random Sampler \n",
    "from training.utils import define_weighted_random_sampler \n",
    "\n",
    "weighted_sampler, class_weights_dict = define_weighted_random_sampler(\n",
    "        dataset=train_data, \n",
    "        mask_key=\"mask\", \n",
    "        subset_size=200,\n",
    "        seed=42\n",
    "    )\n",
    "print(\"Class Weights : \", class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weights = [class_weights_dict[i] for i in range(len(class_weights_dict))]\n",
    "class_weights = [1.0, 20.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dl = DataLoader(dataset=train_data, batch_size=32, pin_memory=True, num_workers=8) #sampler=weighted_sampler)\n",
    "val_dl = DataLoader(dataset=val_data, shuffle=True, batch_size=32, pin_memory=True, num_workers=8)\n",
    "test_dl = DataLoader(dataset=test_data, shuffle=False, batch_size=32, pin_memory=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import train, testing\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch \n",
    "from metrics import iou_score, f1_score, precision, recall\n",
    "import torch.optim as optim\n",
    "from losses import Ensemble, DiceLoss\n",
    "\n",
    "mode = \"multiclass\"\n",
    "nb_epochs = 3\n",
    "\n",
    "criterion = Ensemble(\n",
    "    list_losses=[\n",
    "        torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights), reduction='mean').to(\"cuda\"), \n",
    "        DiceLoss(mode=mode)\n",
    "    ],\n",
    "    weights=[0.7,0.3]\n",
    ")\n",
    "metrics = [f1_score, iou_score]\n",
    "\n",
    "optimizer = optim.AdamW\n",
    "params_opt = {\"lr\":1e-3, \"weight_decay\":1e-2, \"amsgrad\": False}\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR\n",
    "params_sc = {\"T_max\" : 100}\n",
    "early_stopping_params = {\"patience\": 5, \"trigger_times\": 0}\n",
    "\n",
    "train(\n",
    "    model = model,\n",
    "    train_dl = train_dl,\n",
    "    valid_dl = val_dl,\n",
    "    test_dl = test_dl, \n",
    "    loss_fn = criterion,\n",
    "    optimizer = optimizer, \n",
    "    scheduler = scheduler, \n",
    "    params_opt=params_opt,\n",
    "    params_sc=params_sc,\n",
    "    metrics = metrics,\n",
    "    nb_epochs = nb_epochs,\n",
    "    experiment_name = \"Levir_CD_Siamese_ResNet18_Unet\",\n",
    "    log_dir=\"../runs\",\n",
    "    model_dir=\"../models\",\n",
    "    resume_path=None,\n",
    "    early_stopping_params = early_stopping_params,\n",
    "    image_key = \"post_image\",\n",
    "    mask_key = \"mask\",\n",
    "    num_classes = len(class_weights), \n",
    "    verbose = False,  # Adding verbose flag\n",
    "    checkpoint_interval = 10,  # Add checkpoint interval parameter\n",
    "    debug = False,  # Add debug flag for memory logging, \n",
    "    training_log_interval = 5, \n",
    "    is_mixed_precision=True,\n",
    "    reduction= \"weighted\",\n",
    "    class_weights = class_weights,\n",
    "    class_names=[\"No Change\", \"Change\"], \n",
    "    siamese=True,\n",
    "    tta=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import compute_model_class_performance\n",
    "\n",
    "compute_model_class_performance(\n",
    "    model=model,\n",
    "    dataloader=test_dl,\n",
    "    num_classes=2,\n",
    "    device='cuda',\n",
    "    class_names=[\"No Change\", \"Change\"], \n",
    "    siamese=True,\n",
    "    image_key=\"image\",\n",
    "    mask_key=\"mask\",\n",
    "    average_mode=\"macro\",\n",
    "    output_file=\"../outputs/Levir_CD_Siamese_ResNet34_Unet_with_TTA.txt\",\n",
    "    tta=True\n",
    ")\n",
    "compute_model_class_performance(\n",
    "    model=model,\n",
    "    dataloader=test_dl,\n",
    "    num_classes=2,\n",
    "    device='cuda',\n",
    "    class_names=[\"No Change\", \"Change\"], \n",
    "    siamese=True,\n",
    "    image_key=\"image\",\n",
    "    mask_key=\"mask\",\n",
    "    average_mode=\"macro\",\n",
    "    output_file=\"../outputs/Levir_CD_Siamese_ResNet34_Unet_without_TTA.txt\",\n",
    "    tta=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
