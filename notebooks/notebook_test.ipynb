{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a Jupyter notebook or IPython environment, run this in the first cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as pltbasemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# set up orthographic map projection with\n",
    "# perspective of satellite looking down at 45N, 100W.\n",
    "# use low resolution coastlines.\n",
    "map = Basemap(projection='ortho',lat_0=45,lon_0=-100,resolution='l')\n",
    "# draw coastlines, country boundaries, fill continents.\n",
    "map.drawcoastlines(linewidth=0.25)\n",
    "map.drawcountries(linewidth=0.25)\n",
    "map.fillcontinents(color='coral',lake_color='aqua')\n",
    "# draw the edge of the map projection region (the projection limb)\n",
    "map.drawmapboundary(fill_color='aqua')\n",
    "# draw lat/lon grid lines every 30 degrees.\n",
    "map.drawmeridians(np.arange(0,360,30))\n",
    "map.drawparallels(np.arange(-90,90,30))\n",
    "# make up some data on a regular lat/lon grid.\n",
    "nlats = 73; nlons = 145; delta = 2.*np.pi/(nlons-1)\n",
    "lats = (0.5*np.pi-delta*np.indices((nlats,nlons))[0,:,:])\n",
    "lons = (delta*np.indices((nlats,nlons))[1,:,:])\n",
    "wave = 0.75*(np.sin(2.*lats)**8*np.cos(4.*lons))\n",
    "mean = 0.5*np.cos(2.*lats)*((np.sin(2.*lats))**2 + 2.)\n",
    "# compute native map projection coordinates of lat/lon grid.\n",
    "x, y = map(lons*180./np.pi, lats*180./np.pi)\n",
    "# contour data over the map.\n",
    "cs = map.contour(x,y,wave+mean,15,linewidths=1.5)\n",
    "plt.title('contour lines over filled continent background')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.utils import split_and_save_images\n",
    "\n",
    "for folder_name in [\"train\", \"val\", \"test\"]: \n",
    "        split_and_save_images(\n",
    "                input_dir=f\"../data/Levir-cd/{folder_name}\", \n",
    "                output_dir=f\"../data/Levir-cd-256/{folder_name}\", \n",
    "                patch_size=256, \n",
    "                images_folder_names=[\"A\", \"B\"], \n",
    "                label_folder_name = \"label\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import TinyCD, SiameseResNetUNet\n",
    "\n",
    "model = SiameseResNetUNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dl = DataLoader(dataset=train_data, shuffle=True, batch_size=16, pin_memory=True)\n",
    "val_dl = DataLoader(dataset=val_data, shuffle=True, batch_size=16, pin_memory=True)\n",
    "test_dl = DataLoader(dataset=test_data, shuffle=False, batch_size=16, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import train, testing\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch \n",
    "from metrics import iou_score, f1_score, precision, recall\n",
    "from losses import DiceLoss, Ensemble, FocalLoss\n",
    "import torch.optim as optim\n",
    "from training.utils import define_weighted_random_sampler\n",
    "\n",
    "mode = \"multiclass\"\n",
    "#_ , class_weights_dict = define_weighted_random_sampler(dataset=train_data, mask_key=\"mask\", subset_size=200)\n",
    "class_weights = [1.0, 20.0] # [v for _ , v in class_weights_dict.items()]\n",
    "#print(\"Computed Class Weights : \", class_weights)\n",
    "\n",
    "nb_epochs = 2\n",
    "#ce = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights), reduction='mean').to(\"cuda\")\n",
    "#focal_loss = FocalLoss(mode=mode, gamma=2)\n",
    "#dice_loss = DiceLoss(mode=mode)\n",
    "#criterion = Ensemble(list_losses=[ce, dice_loss], weights = [0.7, 0.3])\n",
    "criterion =  torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights), reduction='mean').to(\"cuda\")\n",
    "\n",
    "metrics = [f1_score, iou_score, precision, recall]\n",
    "\n",
    "optimizer = optim.AdamW(params=filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3, weight_decay=1e-2,amsgrad=False)\n",
    "# scheduler for the lr of the optimizer\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "early_stopping_params = {\"patience\": 10, \"trigger_times\": 0}\n",
    "\n",
    "train(\n",
    "    model = model,\n",
    "    train_dl = train_dl,\n",
    "    valid_dl = val_dl,\n",
    "    loss_fn = criterion,\n",
    "    optimizer = optimizer, \n",
    "    scheduler = scheduler, \n",
    "    metrics = metrics,\n",
    "    nb_epochs = nb_epochs,\n",
    "    experiment_name = \"Tiny_CD\",\n",
    "    log_dir=\"../runs\",\n",
    "    model_dir=\"../models\",\n",
    "    resume_path=None,\n",
    "    early_stopping_params = early_stopping_params,\n",
    "    image_key = \"post_image\",\n",
    "    mask_key = \"mask\",\n",
    "    num_classes = len(class_weights), \n",
    "    verbose = False,  # Adding verbose flag\n",
    "    checkpoint_interval = 5,  # Add checkpoint interval parameter\n",
    "    debug = False,  # Add debug flag for memory logging, \n",
    "    training_log_interval = 2, \n",
    "    is_mixed_precision=True,\n",
    "    reduction= \"weighted\",\n",
    "    class_weights = class_weights,\n",
    "    siamese=True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import compute_model_class_performance\n",
    "\n",
    "compute_model_class_performance(\n",
    "    model=model,\n",
    "    dataloader=test_dl,\n",
    "    num_classes=2,\n",
    "    device='cuda',\n",
    "    class_names=[\"No Change\", \"Change\"], \n",
    "    siamese=True,\n",
    "    image_key=\"image\",\n",
    "    mask_key=\"mask\",\n",
    "    average_mode=\"macro\",\n",
    "    output_file=\"../outputs/class_performance.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Ensemble Methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "test_dl = DataLoader(\n",
    "    dataset=test_dl,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_models(\n",
    "    models,\n",
    "    models_names,\n",
    "    test_dataloader,\n",
    "    loss_fn,\n",
    "    metrics,\n",
    "    image_key=\"post_image\",\n",
    "    mask_key=\"post_mask\",\n",
    "    verbose=True,\n",
    "    is_mixed_precision=True,\n",
    "    num_classes=5,\n",
    "    reduction=\"weighted\",\n",
    "    class_weights=None,\n",
    "    tta=False,\n",
    "    siamese=False,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Benchmark multiple models on a test dataloader.\n",
    "\n",
    "    Args:\n",
    "        models (list): List of models to evaluate.\n",
    "        models_names (list): List of model's name\n",
    "        test_dataloader (DataLoader): PyTorch DataLoader with test data.\n",
    "        loss_fn (callable): Loss function.\n",
    "        metrics (dict): Dictionary of metric functions to evaluate.\n",
    "        image_key (str): Key to access image data from the dataloader batch.\n",
    "        mask_key (str): Key to access mask/label data from the dataloader batch.\n",
    "        verbose (bool): If True, print detailed logs for each model.\n",
    "        is_mixed_precision (bool): Use mixed precision during evaluation.\n",
    "        num_classes (int): Number of classes in the task.\n",
    "        reduction (str): Reduction method for metrics (e.g., \"weighted\").\n",
    "        class_weights (torch.Tensor): Class weights for loss computation.\n",
    "        tta (bool): Apply test-time augmentation if True.\n",
    "        siamese (bool): Use Siamese model logic if True.\n",
    "        device (str) : cuda or cpu\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing test losses and metrics for each model.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        if verbose:\n",
    "            print(f\"/nEvaluating Model {i+1}/{len(models)}: {models_names[i]}\")\n",
    "        \n",
    "        # Test the model using the provided testing function\n",
    "        epoch_tloss, test_metrics = testing(\n",
    "            model=model.to(device),\n",
    "            test_dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            metrics=metrics,\n",
    "            image_key=image_key,\n",
    "            mask_key=mask_key,\n",
    "            verbose=verbose,\n",
    "            is_mixed_precision=is_mixed_precision,\n",
    "            num_classes=num_classes,\n",
    "            reduction=reduction,\n",
    "            class_weights=class_weights,\n",
    "            tta=tta,\n",
    "            siamese=siamese,\n",
    "        )\n",
    "\n",
    "        # Store results\n",
    "        results[models_names[i]] = {\n",
    "            \"test_loss\": epoch_tloss,\n",
    "            \"test_metrics\": test_metrics,\n",
    "        }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_semantic_predictions_batch(\n",
    "    images=post_image, \n",
    "    mask_predictions=outputs.argmax(dim=1),\n",
    "    mask_labels=inputs[\"post_mask\"],\n",
    "    normalized={\n",
    "        \"mean\" : (0.485, 0.456, 0.406),\n",
    "        \"std\" : (0.229, 0.224, 0.225)\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_semantic_predictions_batch(\n",
    "    images=pre_image, \n",
    "    mask_predictions=tta_predictions,\n",
    "    mask_labels=inputs[\"post_mask\"],\n",
    "    normalized={\n",
    "        \"mean\" : (0.485, 0.456, 0.406),\n",
    "        \"std\" : (0.229, 0.224, 0.225)\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Segformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Segformer, Unet, ResNet_Unet\n",
    "model_name = \"nvidia/segformer-b0-finetuned-ade-512-512\"\n",
    "label2id = {\"building\": 1, \"background\": 0 } #{\"cloud\": 1, \"no_cloud\": 0 }\n",
    "id2label = {v: k for k,v in label2id.items()}\n",
    "num_labels = 2\n",
    "freeze_encoder = True\n",
    "\n",
    "model = Segformer(model_name=model_name,\n",
    "                  label2id=label2id,\n",
    "                  num_labels=num_labels,\n",
    "                  freeze_encoder=freeze_encoder\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import  Puerto_Rico_Building_Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from training.augmentations import get_val_augmentation_pipeline\n",
    "\n",
    "# Define Albumentations transforms with normalization\n",
    "transform = get_val_augmentation_pipeline(image_size=(512, 512), max_pixel_value=1, mean=(0,0,0), std=(1,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import AutoEncoder\n",
    "from training.augmentations import get_val_augmentation_pipeline\n",
    "import torch.nn as nn\n",
    "\n",
    "cloud_filter_params = {\"model_class\": AutoEncoder(num_input_channel=3,base_channel_size=64), \n",
    "                        \"device\": \"cuda\", \n",
    "                        \"file_path\": \"../models/AutoEncoder_Cloud_Detector_0.001297.pth\",\n",
    "                        \"threshold\": 0.001297, \n",
    "                        \"loss\": nn.MSELoss,\n",
    "                        \"batch_size\": 32\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_puerto = Puerto_Rico_Building_Dataset(\n",
    "    base_dir=\"../data/Puerto_Rico_dataset/tiff_tiles\",\n",
    "    pre_disaster_dir=\"Pre_Event_Grids_In_TIFF\",\n",
    "    post_disaster_dir=\"Post_Event_Grids_In_TIFF\",\n",
    "    mask_dir=\"Post_Event_Grids_In_TIFF_mask\",\n",
    "    transform=transform,\n",
    "    extension=\"tif\",\n",
    "    cloud_filter_params=cloud_filter_params,\n",
    "    preprocessing_mode=\"online\",\n",
    "    filtered_list_path=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ResNet_UNET\n",
    "\n",
    "model = ResNet_UNET(\n",
    "        in_channels=3,\n",
    "        out_channels=2,\n",
    "        backbone_name=\"resnet18\",\n",
    "        pretrained=True,\n",
    "        freeze_backbone=True,\n",
    "    )\n",
    "model = model.load(file_path=\"../models/xDB_ResNet18_Unet_20241130-201241_best_model.pth\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dl = DataLoader(dataset=data_puerto, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = next(iter(data_dl))\n",
    "outputs = model.predict(inputs[\"pre_image\"].to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import display_semantic_predictions_batch\n",
    "\n",
    "display_semantic_predictions_batch(images=inputs[\"pre_image\"], \n",
    "                                    mask_predictions=outputs,\n",
    "                                    mask_labels=inputs[\"mask\"], \n",
    "                                    normalized=None, \n",
    "                                    folder_path=None\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Maskrcnn\n",
    "# Initialize the Mask R-CNN model\n",
    "from models import Maskrcnn\n",
    "maskrcnn = Maskrcnn(num_classes=2, hidden_layer_dim=256, pretrained=False)\n",
    "maskrcnn.load(\"../models/xDB_ResNet50_MaskRCNN_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import display_semantic_predictions_batch\n",
    "import numpy as np\n",
    "import torch\n",
    "maskrcnn.eval()\n",
    "with torch.no_grad():\n",
    "    images = inputs[\"pre_image\"].to(\"cuda\")\n",
    "    mask_predictions = maskrcnn.predict_sem_seg(images = images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_semantic_predictions_batch(images=inputs[\"pre_image\"], \n",
    "                                    mask_predictions=mask_predictions,\n",
    "                                    mask_labels=inputs[\"mask\"], \n",
    "                                    normalized=None, \n",
    "                                    folder_path=None\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import display_instance_predictions_batch\n",
    "maskrcnn.eval()\n",
    "with torch.no_grad():\n",
    "    images = inputs[\"pre_image\"].to(\"cuda\")\n",
    "    instances_predictions = maskrcnn.predict(images = images)\n",
    "    \n",
    "display_instance_predictions_batch(images, mask_predictions, score_threshold=0.6, max_images=len(images), display=[\"mask\",\"boxes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Processing techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SiameseResNetUNet\n",
    "model = SiameseResNetUNet(\n",
    "    in_channels=3,\n",
    "    out_channels=5,\n",
    "    backbone_name=\"resnet18\",\n",
    "    pretrained=True,\n",
    "    freeze_backbone=False,\n",
    "    mode=\"conc\")\n",
    "model = model.load(\"../models/Siamese_ResNet18_Unet_20241206-152757_best_model.pth\")\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [f\"../data/xDB/tier3/images/joplin-tornado_0000000{i}_pre_disaster.png\" for i in range(0,5)]\n",
    "pre_images = [Image.open(file_path).convert('RGB') for file_path in file_paths]\n",
    "file_paths = [f\"../data/xDB/tier3/images/joplin-tornado_0000000{i}_post_disaster.png\" for i in range(0,5)]\n",
    "post_images = [Image.open(file_path).convert('RGB') for file_path in file_paths]\n",
    "\n",
    "big_image_pre = merge_images(pre_images)\n",
    "big_image_post = merge_images(post_images)\n",
    "\n",
    "inference = Inference(\n",
    "        model=model, \n",
    "        pre_image=big_image_pre, \n",
    "        post_image=big_image_post,\n",
    "        window_size=512, \n",
    "        num_classes=5,\n",
    "        stride=100, \n",
    "        device ='cuda', \n",
    "        mode=\"siamese\",\n",
    "        transform=transforms.Compose([\n",
    "            v2.ToImage(),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(mean=[0.349, 0.354, 0.268], std=[0.114, 0.102, 0.094]),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "prediction = inference.infer().argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_colors = {\n",
    "        0: (0, 0, 0),      # Black for background\n",
    "        1: (0, 255, 0),    # Green for no-damage\n",
    "        2: (255, 255, 0),  # Yellow for minor-damage\n",
    "        3: (255, 126, 0),  # Orange for major-damage\n",
    "        4: (255, 0, 0)     # Red for destroyed\n",
    "    }\n",
    "\n",
    "plot_results_building(image=big_image_post, prediction=prediction, color_dict = damage_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Levir_cd_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.L_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.display_data(list_indices=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.augmentations import (\n",
    "    get_val_augmentation_pipeline )\n",
    "\n",
    "transform = get_val_augmentation_pipeline(image_size = (512, 512))\n",
    "data = Levir_cd_dataset(origin_dir=\"../data/data_samples/Levir-cd\", type=\"test\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_coordinates(filename, folderpath : str = None):\n",
    "    \"\"\"\n",
    "    Extracts the x and y coordinates from a filename like 'train_1_0_256.png'.\n",
    "    \n",
    "    Returns:\n",
    "        (x, y): Tuple of integers representing coordinates.\n",
    "    \"\"\"\n",
    "    filename = os.path.join(folderpath if folderpath is not None else \"\", filename)\n",
    "    # Use regex to extract all numeric components\n",
    "    parts = filename.replace('.png', '').split('_')\n",
    "    print(parts)\n",
    "    x = int(parts[2])\n",
    "    y = int(parts[3])\n",
    "    return (x, y)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "filename = \"train_1_0_256.png\"\n",
    "coords = extract_coordinates(filename)\n",
    "print(coords)  # Output: (0, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "bands = [1, 2, 3]\n",
    "image_file = \"tile_0_0.tif\"\n",
    "with rasterio.open(f\"../data/processed_data/Post_Event_San_Juan_sample/{image_file}\") as dataset:\n",
    "    base_image = np.transpose(dataset.read(bands), (1, 2, 0))\n",
    "\n",
    "with rasterio.open(f\"../data/predictions/{image_file}\") as dataset:\n",
    "    preds = np.transpose(dataset.read([1, 2, 3, 4]), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with rasterio \n",
    "# access to \n",
    "# bounds : dst.bounds.left, top , right, bottom\n",
    "# affine transform (map image pixels to CRS (a projected reference in a specific location (expressed in meters)) with an affine transformation)\n",
    "# crs (here : EPSG:32619)\n",
    "# image bands => .read => numpy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing mode : \n",
    "# driver# width and height\n",
    "# count : number of bands \n",
    "# dtype : data type of dataset\n",
    "# crs : coordinate system \n",
    "# transform affine transformation\n",
    "# nodata \n",
    "\n",
    "# Every band in a dataset get a mask = src.read_masks(num_band)\n",
    "#   0 : nodata regiion , 255 : valid data region \n",
    "# some nodata value can appear in the valid data region because of issue conversion \n",
    "# if dataset have some 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "i_min, i_max = 0, 10\n",
    "j_min, j_max = 0, 10\n",
    "folder_path = \"../data/predictions\"\n",
    "\n",
    "def extract_tile_ij(filename: str):\n",
    "    pattern = r\"^tile_(\\d+)_(\\d+)\\.tif$\"\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        return int(match.group(1)), int(match.group(2))\n",
    "    return None, None\n",
    "\n",
    "def filter_list(filename: str):\n",
    "    i, j = extract_tile_ij(filename)\n",
    "    if i is None or j is None:\n",
    "        return False\n",
    "    return (i_min <= i <= i_max) and (j_min <= j <= j_max)\n",
    "\n",
    "def build_list_file(folder: str):\n",
    "    absolute_path = os.path.abspath(folder)\n",
    "    file_list = [\n",
    "        os.path.join(absolute_path, f)\n",
    "        for f in os.listdir(absolute_path)\n",
    "        if filter_list(f)\n",
    "    ]\n",
    "    return file_list\n",
    "\n",
    "# Example usage:\n",
    "filtered_files = build_list_file(folder_path)\n",
    "print(filtered_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
